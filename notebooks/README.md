

---

# üìä Proyecto de Clasificaci√≥n de Puntaje Crediticio

¬°Hola! Este es mi informe sobre el proceso completo que segu√≠ para analizar, limpiar, mejorar y modelar un dataset de puntajes crediticios. Desde el an√°lisis exploratorio (EDA) hasta la selecci√≥n de modelos, te cuento cada paso que di para predecir **`Puntaje_Credito_Num`** con la mayor precisi√≥n posible. Vamos all√°.

---

## üåü Objetivo
Mi meta fue construir un modelo que prediga **`Puntaje_Credito_Num`** (0: Poor, 1: Standard, 2: Good) usando caracter√≠sticas financieras y demogr√°ficas, alcanzando una precisi√≥n cercana al 89-90%. Trabaj√© con RandomForestClassifier y XGBoost, ajustando datos y par√°metros en el camino.

---

## üõ†Ô∏è Proceso Paso a Paso

Aqu√≠ est√° la lista detallada de todo lo que hice, desde el EDA hasta el modelado final:

### 1. üìà An√°lisis Exploratorio de Datos (EDA)
- **Cargu√© el Dataset**: Import√© mi dataset con pandas para verlo en acci√≥n.
- **Explor√© Columnas**: Identifiqu√© variables num√©ricas (como `Salario_Mensual`, `Deuda_Pendiente`) y categ√≥ricas (como `Ocupacion`, `Comportamiento_Pago`).
- **Detect√© Nulos**: Revis√© valores faltantes y decid√≠ c√≥mo manejarlos (relleno o eliminaci√≥n seg√∫n el caso).
- **Distribuciones**: Grafiqu√© histogramas y boxplots para entender la dispersi√≥n y detectar outliers.
- **Correlaciones**: Us√© un mapa de calor para ver relaciones entre variables num√©ricas.

### 2. üßπ Limpieza de Datos
- **Elimin√© Duplicados**: Me asegur√© de que no hubiera filas repetidas.
- **Manej√© Nulos**: Rellen√© valores faltantes en columnas num√©ricas con la mediana (ej. `Salario_Mensual`) y en categ√≥ricas con la moda (ej. `Ocupacion`).
- **Outliers**: Apliqu√© recorte (clipping) a valores extremos en columnas como `Deuda_Pendiente` usando percentiles 1% y 99%.

### 3. üîß Mejoramiento de Datos (Feature Engineering)
- **Cre√© Nuevas Caracter√≠sticas**:
  - `credit_history_ratio`: Relaci√≥n entre historial crediticio y edad.
  - `credit_usage_to_limit`: Uso del cr√©dito respecto al l√≠mite.
  - `debt_to_income`: Deuda respecto al ingreso.
  - `payment_to_income`: Pagos respecto al ingreso.
  - `delay_ratio`: Proporci√≥n de retrasos en pagos.
- **Codifiqu√© Variables**:
  - **OneHotEncoder**: Transform√© `Ocupacion` (ej. Doctor, Engineer) y `Comportamiento_Pago` (Bajo Impacto, Intermedio, Responsable) en columnas binarias.
  - **Codificaci√≥n Manual**: Convert√≠ `Mezcla_Crediticia` y `Pago_Minimo` en valores num√©ricos (ej. `Mezcla_Crediticia_Cod`, `Pago_Minimo_Cod`).

### 4. üóëÔ∏è Eliminaci√≥n de Columnas
- **Columnas Redundantes**: Elimin√© columnas originales tras crear nuevas caracter√≠sticas (ej. componentes de `credit_usage_to_limit`).
- **Baja Importancia**: Descart√© variables con poca relevancia inicial (basado en EDA), como algunas ocupaciones poco frecuentes si no aportaban.

### 5. üìè Escalado de Columnas Num√©ricas
- **StandardScaler**: Escalo columnas num√©ricas (ej. `Salario_Mensual`, `Deuda_Pendiente`, `Tasa_Interes`) para que tengan media 0 y desviaci√≥n 1, mejorando el rendimiento del modelo.

### 6. üîç Divisi√≥n y Optimizaci√≥n
- **Train-Test Split**: Divid√≠ el dataset en 80% entrenamiento y 20% prueba con `stratify=y` para mantener las proporciones de `Puntaje_Credito_Num`.
- **RandomForestClassifier**: Prob√© m√∫ltiples configuraciones con `RandomizedSearchCV`, ajustando `n_estimators`, `max_depth`, `min_samples_split`, etc.
- **XGBoost**: Explor√© este modelo para buscar mayor precisi√≥n, pero no cumpli√≥ expectativas.

### 7. üìä Evaluaci√≥n y Selecci√≥n
- **M√©tricas Iniciales**: Us√© `accuracy`, `f1_macro`, y `f1_per_class` para evaluar.
- **M√©tricas Finales**: A√±ad√≠ `precision_macro`, `recall_macro`, `balanced_accuracy`, `roc_auc_ovr`, y `confusion_matrix` para un an√°lisis completo.
- **Resultados**: RandomForest alcanz√≥ un m√°ximo de 83.1%, mientras XGBoost se qued√≥ en 81.96%.

---

## üéØ Selecci√≥n de los Dos Mejores Modelos RandomForestClassifier

Escog√≠ dos configuraciones de RandomForestClassifier porque dieron los mejores resultados tras muchas iteraciones:

1. **Modelo 1 (83.01%)**:
   - `n_estimators: 600`, `max_depth: 30`, `min_samples_split: 5`, `class_weight: 'balanced_subsample'`.
   - F1 Macro: 0.823, con buen balance entre clases.
2. **Modelo 2 (83.1%)**:
   - `n_estimators: 800`, `max_depth: 30`, `min_samples_split: 5`, `class_weight: 'balanced_subsample'`.
   - F1 Macro: 0.824, mi mejor marca.

Los seleccion√© por su alta precisi√≥n, balance entre clases (especialmente en "Poor"), y estabilidad en las m√©tricas. RandomForest super√≥ consistentemente otras opciones.

---

## üòï XGBoost: No Cumpli√≥ Expectativas

Prob√© XGBoost esperando un salto hacia 89-90%, pero se qued√≥ en 81.96% de precisi√≥n y 0.808 de F1 Macro. Aunque optimic√© par√°metros como `n_estimators` y `max_depth`, no captur√≥ las relaciones tan bien como RandomForest con este dataset. Creo que el desbalance o la complejidad de las caracter√≠sticas favorecieron m√°s a RandomForest.

---

## üìú Creaci√≥n de Archivos de Configuraci√≥n Simplificados

Finalmente, cre√© dos archivos `.yaml` simplificados para documentar mis mejores modelos:
- **`rf_config_1_simplified.yaml`**: Refleja el Modelo 1 con sus par√°metros √≥ptimos.
- **`rf_config_2_simplified.yaml`**: Refleja el Modelo 2, mi campe√≥n.
- **Por Qu√© Simplificados**: Quit√© el `search_space` y `optimization` porque ya los prob√© en los notebooks, dejando solo los par√°metros finales y m√©tricas clave para uso directo.

Estos archivos son mi resumen final, listos para implementar o compartir.

---

## üöÄ Conclusi√≥n

Llegu√© a un tope de 83.1% con RandomForest, y aunque no alcanc√© un poco mas, estoy satisfecho con el proceso: limpi√©, mejor√© y optimic√© al m√°ximo este dataset. Si tuviera m√°s datos o nuevas caracter√≠sticas, podr√≠a ir m√°s lejos, pero por ahora, ¬°mis dos modelos son aceptables! ¬øQu√© te parecen?